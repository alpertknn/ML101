{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3386730d",
   "metadata": {},
   "source": [
    "# <font color=\"orange\">Introduction to Big Data</font>\n",
    "->> The datas which cannot be processes by traditional methods because of data is changed fastly, datas type and data size.\n",
    "<br>\n",
    "->> The solution of this problem is gathering more computers together, shortly all computers are behaved as one computer.\n",
    "<br>\n",
    "### <font color=\"red\">Advantages</font>\n",
    "->> Data Analytics area has been expanded.\n",
    "<br>\n",
    "->> By enhanced calculations, machine learning algorithms performance is increased.\n",
    "<br>\n",
    "->> By using big data, the significant tool is provided for extracting useful information from data.\n",
    "<br>\n",
    "### <font color=\"purple\">Components of Big Data</font>\n",
    "->> Data Analytics area has been expanded.\n",
    "<br>\n",
    "<img src=\"./used_images/big_data.png\" width=\"400\" height=\"400\">\n",
    "->> The generated data process difficulty is related to data's volume, variety, and velocity.\n",
    "<br>\n",
    "->> The specifications that explains big data are volume, variety, and velocity.\n",
    "<br>\n",
    "->> The most prevalent situation is that when this specifications with big data, that time we can say data is big.\n",
    "<br>\n",
    "->> The tools of big data are very strong to extract useful information from that data.\n",
    "<br>\n",
    "->> Our problem is extracting useful information from data, by big data we can have a solution by using different tools and methods.\n",
    "# <font color=\"orange\">Apache Hadoop</font>\n",
    "->> Apache Hadoop is a software project that opensource,reliable and scalable parallel calculations.\n",
    "<br>\n",
    "->> It creates tha base of Big Data\n",
    "<br>\n",
    "->> It provides an opportunity to be processed to datas which cannot be processed by traditional methods.\n",
    "<br>\n",
    "->> It provides computer cluster to behave as a one computer to do a job.\n",
    "### <font color=\"purple\">Components of Apache Hadoop</font>\n",
    "->> <b>Hadoop Common ->></b> It supports hadoop modules and big data technologies.\n",
    "<br>\n",
    "->> <b>Hadoop Distributed File System (HDFS)->></b> It is a file system like NTFS and FAT32. It provides datas to be stored as distributed, and to conrol.\n",
    "<br>\n",
    "->> <b>Hadoop YARN ->></b> It is a component that makes Apache Hadoop more efficient on Source Management and Work-Planning.\n",
    "<br>\n",
    "->> <b>Hadoop MapReduce ->></b> It is a component that creates big data's base on functional side, and also this is a programming model that makes big data analysis on distributed clustered computers which are placed on same network.\n",
    "### <font color=\"purple\">Apache Hadoop Cluster Structure</font>\n",
    "<img src=\"./used_images/cluster.png\" width=\"400\" height=\"400\">\n",
    "->> The master node is administrator of this network, it sends to jobs other computer and the done job is evaluated.\n",
    "\n",
    "### <font color=\"red\">What is MapReduce</font>\n",
    "<img src=\"./used_images/mapreduce.png\" width=\"600\" height=\"600\">\n",
    "->> As we can see, we have an input and the first thing is it needs to be splitted.\n",
    "<br>\n",
    "->> After splitting, the data is sent to mapping, mappings responsibility is to process input datas on HDFS (Hadoop Distributed File System). After processing, it created new data parts.\n",
    "<br>\n",
    "->> On Shuffling and Reducing part the data, which is transmitted from Mapping is processed and degraded.\n",
    "<br>\n",
    "->> Then the processed data is merged.\n",
    "\n",
    "### <font color=\"red\">Advantages of Apache Hadoop </font>\n",
    "->> Data Storing and Process power\n",
    "<br>\n",
    "->> Open Source\n",
    "<br>\n",
    "->> Fast\n",
    "<br>\n",
    "->> Flexible\n",
    "<br>\n",
    "->> Scalable\n",
    "<br>\n",
    "->> Error Tolerance\n",
    "<br>\n",
    "### <font color=\"red\">Does Apache Hadoop is enough for solution ? </font>\n",
    "->> It is disk-based model.\n",
    "<br>\n",
    "->> In every MapReduce instruction, read and write processes are done on the disk.\n",
    "<br>\n",
    "->> Iterations takes time and makes busy to sources.\n",
    "<img src=\"./used_images/disk.png\" width=\"600\" height=\"600\">\n",
    "\n",
    "# <font color=\"orange\">Apache Spark</font>\n",
    "->> Apache spark is fast, and general purpused information process system on cluster, this is an alternative of MapReduce programming model. It has a in-memory working principal.\n",
    "<br>\n",
    "->> Apache Spark is created because of Disk-Based costs of MapReduced programming model.\n",
    "<br>\n",
    "->> It is 100 times fast to Apache Hadoop\n",
    "<br>\n",
    "->> Any application can be developed with Java, Scala, Python, and R .\n",
    "<br>\n",
    "->> SparkSQL, Spark MLlib, Spark Streaming, GrapX can be used in same application.\n",
    "\n",
    "### <font color=\"red\">Components of Apache Spark</font>\n",
    "->> Spark Core and RDD =>> Splitting instructions, recovery of error, accessing to file system, and memory management is belong to Spark Core part.\n",
    "<br>\n",
    "->> RDD is alternative of MapReduce, also called as, Apache sparks programming model is holded in-memory and processed parallel.\n",
    "<br>\n",
    "->> Spark SQL provides the structured data query by using SQL or Dataframe API on Spark programs.\n",
    "<br>\n",
    "->> Spark MLlib is a machine learning library. \n",
    "<br>\n",
    "->> Spark Streaming provides scalable processing to data which streaming data, and has high volume and error. Also it is  an spark extension that belongs to basic Spark API.\n",
    "<br>\n",
    "->> GrapX is used for Parallel graphich based calculations.\n",
    "\n",
    "#### <font color=\"purple\">A Resilient Distributed Dataset (RDD)</font>\n",
    "\n",
    "<img src=\"./used_images/rdd.png\" width=\"600\" height=\"600\">\n",
    "->> In MapReduce, we do read and write processes on disk\n",
    "<br>\n",
    "->> On RDD, we transfer to process to RAM, which is done on RDD. On RAM, we do transformation and iterative processes then after finish this process, we again write this data to disk.\n",
    "<img src=\"./used_images/difference.png\" width=\"600\" height=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e47b3c40",
   "metadata": {},
   "source": [
    "# <font color=\"orange\">Big Data Manipulation and Visualisation</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f6fb581f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init(\"C:/spark\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2bac8eb0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.conf import SparkConf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8d958294",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialization of Spark Application\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.conf import SparkConf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "08d212fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://MSI:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.3.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>introduction_to_pyspark</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=local appName=introduction_to_pyspark>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Informations of Spark Connection\n",
    "spark = SparkSession.builder \\\n",
    "        .master(\"local\") \\\n",
    "        .appName(\"introduction_to_pyspark\") \\\n",
    "        .getOrCreate()\n",
    "\n",
    "\n",
    "sc = spark.sparkContext\n",
    "sc\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3e9f97b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.3.0\n",
      "introduction_to_pyspark\n"
     ]
    }
   ],
   "source": [
    "print(sc.version)\n",
    "print(sc.appName)\n",
    "sc.stop() # to stop spark, connection should be stopped when finish work"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37ff0b42",
   "metadata": {},
   "source": [
    "### <font color=\"red\">Basic DataFrame Processes</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f80d021b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "import seaborn as sns\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.conf import SparkConf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "029dfcc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://MSI:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.3.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>introduction_to_pyspark</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=local appName=introduction_to_pyspark>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark = SparkSession.builder \\\n",
    "        .master(\"local\") \\\n",
    "        .appName(\"introduction_to_pyspark\") \\\n",
    "        .getOrCreate()\n",
    "sc = spark.sparkContext\n",
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "66a8b22b",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark_df = spark.read.csv(\"./csv_files/churn.csv\",header=True,inferSchema=True) # Read Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4e4b9d04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _c0: integer (nullable = true)\n",
      " |-- Names: string (nullable = true)\n",
      " |-- Age: double (nullable = true)\n",
      " |-- Total_Purchase: double (nullable = true)\n",
      " |-- Account_Manager: integer (nullable = true)\n",
      " |-- Years: double (nullable = true)\n",
      " |-- Num_Sites: double (nullable = true)\n",
      " |-- Churn: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark_df.printSchema() # gives information about dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "516d5cfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(spark_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "45174814",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[_c0: int, Names: string, Age: double, Total_Purchase: double, Account_Manager: int, Years: double, Num_Sites: double, Churn: int]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark_df.cache() # To cache it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4052230e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------------------+----+--------------+---------------+-----+---------+-----+\n",
      "|_c0|              Names| Age|Total_Purchase|Account_Manager|Years|Num_Sites|Churn|\n",
      "+---+-------------------+----+--------------+---------------+-----+---------+-----+\n",
      "|  0|   Cameron Williams|42.0|       11066.8|              0| 7.22|      8.0|    1|\n",
      "|  1|      Kevin Mueller|41.0|      11916.22|              0|  6.5|     11.0|    1|\n",
      "|  2|        Eric Lozano|38.0|      12884.75|              0| 6.67|     12.0|    1|\n",
      "|  3|      Phillip White|42.0|       8010.76|              0| 6.71|     10.0|    1|\n",
      "|  4|     Cynthia Norton|37.0|       9191.58|              0| 5.56|      9.0|    1|\n",
      "|  5|   Jessica Williams|48.0|      10356.02|              0| 5.12|      8.0|    1|\n",
      "|  6|        Eric Butler|44.0|      11331.58|              1| 5.23|     11.0|    1|\n",
      "|  7|      Zachary Walsh|32.0|       9885.12|              1| 6.92|      9.0|    1|\n",
      "|  8|        Ashlee Carr|43.0|       14062.6|              1| 5.46|     11.0|    1|\n",
      "|  9|     Jennifer Lynch|40.0|       8066.94|              1| 7.11|     11.0|    1|\n",
      "| 10|       Paula Harris|30.0|      11575.37|              1| 5.22|      8.0|    1|\n",
      "| 11|     Bruce Phillips|45.0|       8771.02|              1| 6.64|     11.0|    1|\n",
      "| 12|       Craig Garner|45.0|       8988.67|              1| 4.84|     11.0|    1|\n",
      "| 13|       Nicole Olson|40.0|       8283.32|              1|  5.1|     13.0|    1|\n",
      "| 14|     Harold Griffin|41.0|       6569.87|              1|  4.3|     11.0|    1|\n",
      "| 15|       James Wright|38.0|      10494.82|              1| 6.81|     12.0|    1|\n",
      "| 16|      Doris Wilkins|45.0|       8213.41|              1| 7.35|     11.0|    1|\n",
      "| 17|Katherine Carpenter|43.0|      11226.88|              0| 8.08|     12.0|    1|\n",
      "| 18|     Lindsay Martin|53.0|       5515.09|              0| 6.85|      8.0|    1|\n",
      "| 19|        Kathy Curry|46.0|        8046.4|              1| 5.69|      8.0|    1|\n",
      "+---+-------------------+----+--------------+---------------+-----+---------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark_df.show(truncate=True) # To showthe dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "41acde5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "900"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark_df.count() # To number of observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "bbdcabc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['_c0',\n",
       " 'Names',\n",
       " 'Age',\n",
       " 'Total_Purchase',\n",
       " 'Account_Manager',\n",
       " 'Years',\n",
       " 'Num_Sites',\n",
       " 'Churn']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark_df.columns #To show columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "69493a35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+\n",
      "|summary|              Age|\n",
      "+-------+-----------------+\n",
      "|  count|              900|\n",
      "|   mean|41.81666666666667|\n",
      "| stddev|6.127560416916251|\n",
      "|    min|             22.0|\n",
      "|    max|             65.0|\n",
      "+-------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark_df.describe(\"Age\").show() # To describe a column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "fe71b73e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------------------+\n",
      "| Age|              Names|\n",
      "+----+-------------------+\n",
      "|42.0|   Cameron Williams|\n",
      "|41.0|      Kevin Mueller|\n",
      "|38.0|        Eric Lozano|\n",
      "|42.0|      Phillip White|\n",
      "|37.0|     Cynthia Norton|\n",
      "|48.0|   Jessica Williams|\n",
      "|44.0|        Eric Butler|\n",
      "|32.0|      Zachary Walsh|\n",
      "|43.0|        Ashlee Carr|\n",
      "|40.0|     Jennifer Lynch|\n",
      "|30.0|       Paula Harris|\n",
      "|45.0|     Bruce Phillips|\n",
      "|45.0|       Craig Garner|\n",
      "|40.0|       Nicole Olson|\n",
      "|41.0|     Harold Griffin|\n",
      "|38.0|       James Wright|\n",
      "|45.0|      Doris Wilkins|\n",
      "|43.0|Katherine Carpenter|\n",
      "|53.0|     Lindsay Martin|\n",
      "|46.0|        Kathy Curry|\n",
      "+----+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark_df.select(\"Age\",\"Names\").show() # To select specific columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "421032c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "524"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark_df.filter(spark_df.Age > 40).count() # To filter a query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "85b3e80e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+\n",
      "|Churn|count|\n",
      "+-----+-----+\n",
      "|    1|  150|\n",
      "|    0|  750|\n",
      "+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark_df.groupby(\"Churn\").count().show() #To group a column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "efa08f49",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----------------+\n",
      "|Churn|         avg(Age)|\n",
      "+-----+-----------------+\n",
      "|    1|42.99333333333333|\n",
      "|    0|41.58133333333333|\n",
      "+-----+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark_df.groupby(\"Churn\").agg({\"Age\":\"mean\"}).show() # To apply a function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e7fad556",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------------+\n",
      "|Churn|count(Churn)|\n",
      "+-----+------------+\n",
      "|    1|         150|\n",
      "|    0|         750|\n",
      "+-----+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark_df.groupby(\"Churn\").agg({\"Churn\":\"count\"}).show() # To apply a function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e547881",
   "metadata": {},
   "source": [
    "### <font color=\"red\">SQL Processes</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "eb163a1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|namespace|\n",
      "+---------+\n",
      "|  default|\n",
      "+---------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\spark\\python\\pyspark\\sql\\dataframe.py:229: FutureWarning: Deprecated in 2.0, use createOrReplaceTempView instead.\n",
      "  warnings.warn(\"Deprecated in 2.0, use createOrReplaceTempView instead.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "spark_df.registerTempTable(\"table_df\") # register our dataframe to sql database as table_df as temporary\n",
    "spark.sql(\"show databases\").show()  # spark.sql for sql queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b1e41cce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+-----------+\n",
      "|namespace|tableName|isTemporary|\n",
      "+---------+---------+-----------+\n",
      "|         | table_df|       true|\n",
      "+---------+---------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"show tables\").show() # To show tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "4ff8215b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+\n",
      "| age|\n",
      "+----+\n",
      "|42.0|\n",
      "|41.0|\n",
      "|38.0|\n",
      "|42.0|\n",
      "|37.0|\n",
      "|48.0|\n",
      "|44.0|\n",
      "|32.0|\n",
      "|43.0|\n",
      "|40.0|\n",
      "|30.0|\n",
      "|45.0|\n",
      "|45.0|\n",
      "|40.0|\n",
      "|41.0|\n",
      "|38.0|\n",
      "|45.0|\n",
      "|43.0|\n",
      "|53.0|\n",
      "|46.0|\n",
      "+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select age from table_df\").show() #To run a basic sql query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "d0c1979e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----------------+\n",
      "|Churn|        mean(Age)|\n",
      "+-----+-----------------+\n",
      "|    1|42.99333333333333|\n",
      "|    0|41.58133333333333|\n",
      "+-----+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select Churn, mean(Age) from table_df group by Churn\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e6040840",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------------+\n",
      "|Churn|count(Churn)|\n",
      "+-----+------------+\n",
      "|    1|         150|\n",
      "|    0|         750|\n",
      "+-----+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select Churn, count(Churn) from table_df group by Churn\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c42062e",
   "metadata": {},
   "source": [
    "### <font color=\"red\">Visualisation on Big Data</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5043655c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e69ec05b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------------------+----+--------------+---------------+-----+---------+-----+\n",
      "|_c0|              Names| Age|Total_Purchase|Account_Manager|Years|Num_Sites|Churn|\n",
      "+---+-------------------+----+--------------+---------------+-----+---------+-----+\n",
      "|  0|   Cameron Williams|42.0|       11066.8|              0| 7.22|      8.0|    1|\n",
      "|  1|      Kevin Mueller|41.0|      11916.22|              0|  6.5|     11.0|    1|\n",
      "|  2|        Eric Lozano|38.0|      12884.75|              0| 6.67|     12.0|    1|\n",
      "|  3|      Phillip White|42.0|       8010.76|              0| 6.71|     10.0|    1|\n",
      "|  4|     Cynthia Norton|37.0|       9191.58|              0| 5.56|      9.0|    1|\n",
      "|  5|   Jessica Williams|48.0|      10356.02|              0| 5.12|      8.0|    1|\n",
      "|  6|        Eric Butler|44.0|      11331.58|              1| 5.23|     11.0|    1|\n",
      "|  7|      Zachary Walsh|32.0|       9885.12|              1| 6.92|      9.0|    1|\n",
      "|  8|        Ashlee Carr|43.0|       14062.6|              1| 5.46|     11.0|    1|\n",
      "|  9|     Jennifer Lynch|40.0|       8066.94|              1| 7.11|     11.0|    1|\n",
      "| 10|       Paula Harris|30.0|      11575.37|              1| 5.22|      8.0|    1|\n",
      "| 11|     Bruce Phillips|45.0|       8771.02|              1| 6.64|     11.0|    1|\n",
      "| 12|       Craig Garner|45.0|       8988.67|              1| 4.84|     11.0|    1|\n",
      "| 13|       Nicole Olson|40.0|       8283.32|              1|  5.1|     13.0|    1|\n",
      "| 14|     Harold Griffin|41.0|       6569.87|              1|  4.3|     11.0|    1|\n",
      "| 15|       James Wright|38.0|      10494.82|              1| 6.81|     12.0|    1|\n",
      "| 16|      Doris Wilkins|45.0|       8213.41|              1| 7.35|     11.0|    1|\n",
      "| 17|Katherine Carpenter|43.0|      11226.88|              0| 8.08|     12.0|    1|\n",
      "| 18|     Lindsay Martin|53.0|       5515.09|              0| 6.85|      8.0|    1|\n",
      "| 19|        Kathy Curry|46.0|        8046.4|              1| 5.69|      8.0|    1|\n",
      "+---+-------------------+----+--------------+---------------+-----+---------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5acf35e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf=spark_df.toPandas() # to convert pandas dataframe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ef4dcc95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_c0</th>\n",
       "      <th>Names</th>\n",
       "      <th>Age</th>\n",
       "      <th>Total_Purchase</th>\n",
       "      <th>Account_Manager</th>\n",
       "      <th>Years</th>\n",
       "      <th>Num_Sites</th>\n",
       "      <th>Churn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Cameron Williams</td>\n",
       "      <td>42.0</td>\n",
       "      <td>11066.80</td>\n",
       "      <td>0</td>\n",
       "      <td>7.22</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Kevin Mueller</td>\n",
       "      <td>41.0</td>\n",
       "      <td>11916.22</td>\n",
       "      <td>0</td>\n",
       "      <td>6.50</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Eric Lozano</td>\n",
       "      <td>38.0</td>\n",
       "      <td>12884.75</td>\n",
       "      <td>0</td>\n",
       "      <td>6.67</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Phillip White</td>\n",
       "      <td>42.0</td>\n",
       "      <td>8010.76</td>\n",
       "      <td>0</td>\n",
       "      <td>6.71</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Cynthia Norton</td>\n",
       "      <td>37.0</td>\n",
       "      <td>9191.58</td>\n",
       "      <td>0</td>\n",
       "      <td>5.56</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   _c0             Names   Age  Total_Purchase  Account_Manager  Years  \\\n",
       "0    0  Cameron Williams  42.0        11066.80                0   7.22   \n",
       "1    1     Kevin Mueller  41.0        11916.22                0   6.50   \n",
       "2    2       Eric Lozano  38.0        12884.75                0   6.67   \n",
       "3    3     Phillip White  42.0         8010.76                0   6.71   \n",
       "4    4    Cynthia Norton  37.0         9191.58                0   5.56   \n",
       "\n",
       "   Num_Sites  Churn  \n",
       "0        8.0      1  \n",
       "1       11.0      1  \n",
       "2       12.0      1  \n",
       "3       10.0      1  \n",
       "4        9.0      1  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(sdf)\n",
    "sdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "81133ac2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_c0                750\n",
       "Names              750\n",
       "Age                750\n",
       "Total_Purchase     750\n",
       "Account_Manager    750\n",
       "Years              750\n",
       "Num_Sites          750\n",
       "Churn              750\n",
       "dtype: int64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sdf[sdf[\"Churn\"]==0].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c4809939",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.barplot(x=\"Churn\",y=sdf.Churn.index,data=sdf);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "90104119",
   "metadata": {},
   "outputs": [],
   "source": [
    "# on big datasets, we should degrade the dataset whatever we do\n",
    "a= spark_df.groupby(\"Churn\").count().toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0f387911",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Churn</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>750</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Churn  count\n",
       "0      1    150\n",
       "1      0    750"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "cf168f36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.barplot(x=\"Churn\",y=\"count\",data=a);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a79f3c8",
   "metadata": {},
   "source": [
    "# <font color=\"orange\">Machine Learning Side</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "6c217b58",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------------+----+--------------+---------------+-----+---------+-----+\n",
      "|_c0|           Names| Age|Total_Purchase|Account_Manager|Years|Num_Sites|Churn|\n",
      "+---+----------------+----+--------------+---------------+-----+---------+-----+\n",
      "|  0|Cameron Williams|42.0|       11066.8|              0| 7.22|      8.0|    1|\n",
      "|  1|   Kevin Mueller|41.0|      11916.22|              0|  6.5|     11.0|    1|\n",
      "|  2|     Eric Lozano|38.0|      12884.75|              0| 6.67|     12.0|    1|\n",
      "|  3|   Phillip White|42.0|       8010.76|              0| 6.71|     10.0|    1|\n",
      "|  4|  Cynthia Norton|37.0|       9191.58|              0| 5.56|      9.0|    1|\n",
      "+---+----------------+----+--------------+---------------+-----+---------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark_df = spark.read.csv(\"./csv_files/churn.csv\",header=True) \n",
    "spark_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "8278caab",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark_df = spark_df.toDF(*[c.lower() for c in spark_df.columns]) # To lovercase columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "dc0fd06f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(spark_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "d7ac51b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark_df = spark_df.withColumnRenamed(\"_c0\",\"index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "bd3f3710",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "900"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark_df.count() # number of obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "4067f0da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(spark_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "7aa49368",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['index',\n",
       " 'names',\n",
       " 'age',\n",
       " 'total_purchase',\n",
       " 'account_manager',\n",
       " 'years',\n",
       " 'num_sites',\n",
       " 'churn']"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "bc7a53d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+-------------+-----------------+-----------------+------------------+-----------------+------------------+-------------------+\n",
      "|summary|             index|        names|              age|   total_purchase|   account_manager|            years|         num_sites|              churn|\n",
      "+-------+------------------+-------------+-----------------+-----------------+------------------+-----------------+------------------+-------------------+\n",
      "|  count|               900|          900|              900|              900|               900|              900|               900|                900|\n",
      "|   mean|             449.5|         null|41.81666666666667|10062.82403333334|0.4811111111111111| 5.27315555555555| 8.587777777777777|0.16666666666666666|\n",
      "| stddev|259.95191863111916|         null|6.127560416916251|2408.644531858096|0.4999208935073339|1.274449013194616|1.7648355920350969| 0.3728852122772358|\n",
      "|    min|                 0|   Aaron King|             22.0|            100.0|                 0|              1.0|              10.0|                  0|\n",
      "|    max|                99|Zachary Walsh|             65.0|           9993.5|                 1|             9.15|               9.0|                  1|\n",
      "+-------+------------------+-------------+-----------------+-----------------+------------------+-----------------+------------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark_df.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "a911ec3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We want to predict that the whether customer will leave us or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "5667d090",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>summary</th>\n",
       "      <td>count</td>\n",
       "      <td>mean</td>\n",
       "      <td>stddev</td>\n",
       "      <td>min</td>\n",
       "      <td>max</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>900</td>\n",
       "      <td>41.81666666666667</td>\n",
       "      <td>6.127560416916251</td>\n",
       "      <td>22.0</td>\n",
       "      <td>65.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_purchase</th>\n",
       "      <td>900</td>\n",
       "      <td>10062.82403333334</td>\n",
       "      <td>2408.644531858096</td>\n",
       "      <td>100.0</td>\n",
       "      <td>9993.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>account_manager</th>\n",
       "      <td>900</td>\n",
       "      <td>0.4811111111111111</td>\n",
       "      <td>0.4999208935073339</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>years</th>\n",
       "      <td>900</td>\n",
       "      <td>5.27315555555555</td>\n",
       "      <td>1.274449013194616</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_sites</th>\n",
       "      <td>900</td>\n",
       "      <td>8.587777777777777</td>\n",
       "      <td>1.7648355920350969</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>churn</th>\n",
       "      <td>900</td>\n",
       "      <td>0.16666666666666666</td>\n",
       "      <td>0.3728852122772358</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     0                    1                   2      3       4\n",
       "summary          count                 mean              stddev    min     max\n",
       "age                900    41.81666666666667   6.127560416916251   22.0    65.0\n",
       "total_purchase     900    10062.82403333334   2408.644531858096  100.0  9993.5\n",
       "account_manager    900   0.4811111111111111  0.4999208935073339      0       1\n",
       "years              900     5.27315555555555   1.274449013194616    1.0    9.15\n",
       "num_sites          900    8.587777777777777  1.7648355920350969   10.0     9.0\n",
       "churn              900  0.16666666666666666  0.3728852122772358      0       1"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark_df.select(\"age\",\"total_purchase\",\"account_manager\",\"years\",\"num_sites\",\"churn\").describe().toPandas().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "b03cebc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark_df=spark_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "848972c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark_df = spark_df.withColumn(\"age_square\",spark_df.age**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "99908f68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------------------+----+--------------+---------------+-----+---------+-----+----------+\n",
      "|index|              names| age|total_purchase|account_manager|years|num_sites|churn|age_square|\n",
      "+-----+-------------------+----+--------------+---------------+-----+---------+-----+----------+\n",
      "|    0|   Cameron Williams|42.0|       11066.8|              0| 7.22|      8.0|    1|    1764.0|\n",
      "|    1|      Kevin Mueller|41.0|      11916.22|              0|  6.5|     11.0|    1|    1681.0|\n",
      "|    2|        Eric Lozano|38.0|      12884.75|              0| 6.67|     12.0|    1|    1444.0|\n",
      "|    3|      Phillip White|42.0|       8010.76|              0| 6.71|     10.0|    1|    1764.0|\n",
      "|    4|     Cynthia Norton|37.0|       9191.58|              0| 5.56|      9.0|    1|    1369.0|\n",
      "|    5|   Jessica Williams|48.0|      10356.02|              0| 5.12|      8.0|    1|    2304.0|\n",
      "|    6|        Eric Butler|44.0|      11331.58|              1| 5.23|     11.0|    1|    1936.0|\n",
      "|    7|      Zachary Walsh|32.0|       9885.12|              1| 6.92|      9.0|    1|    1024.0|\n",
      "|    8|        Ashlee Carr|43.0|       14062.6|              1| 5.46|     11.0|    1|    1849.0|\n",
      "|    9|     Jennifer Lynch|40.0|       8066.94|              1| 7.11|     11.0|    1|    1600.0|\n",
      "|   10|       Paula Harris|30.0|      11575.37|              1| 5.22|      8.0|    1|     900.0|\n",
      "|   11|     Bruce Phillips|45.0|       8771.02|              1| 6.64|     11.0|    1|    2025.0|\n",
      "|   12|       Craig Garner|45.0|       8988.67|              1| 4.84|     11.0|    1|    2025.0|\n",
      "|   13|       Nicole Olson|40.0|       8283.32|              1|  5.1|     13.0|    1|    1600.0|\n",
      "|   14|     Harold Griffin|41.0|       6569.87|              1|  4.3|     11.0|    1|    1681.0|\n",
      "|   15|       James Wright|38.0|      10494.82|              1| 6.81|     12.0|    1|    1444.0|\n",
      "|   16|      Doris Wilkins|45.0|       8213.41|              1| 7.35|     11.0|    1|    2025.0|\n",
      "|   17|Katherine Carpenter|43.0|      11226.88|              0| 8.08|     12.0|    1|    1849.0|\n",
      "|   18|     Lindsay Martin|53.0|       5515.09|              0| 6.85|      8.0|    1|    2809.0|\n",
      "|   19|        Kathy Curry|46.0|        8046.4|              1| 5.69|      8.0|    1|    2116.0|\n",
      "+-----+-------------------+----+--------------+---------------+-----+---------+-----+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "35976fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to show dependent variable\n",
    "\n",
    "# We are assuming that we have a string value and this is a laber or dependent variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "36aa56e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StringIndexer\n",
    "stringIndexer = StringIndexer(inputCol=\"churn\",outputCol=\"label\") \n",
    "# output has to be named as label, we created an object to transform churns to label\n",
    "model= stringIndexer.fit(spark_df)  # fitting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "6a52cf2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "indexed = model.transform(spark_df) # to transformed as indexed\n",
    "spark_df = indexed.withColumn(\"label\",indexed[\"label\"].cast(\"integer\"),) # added to dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "ca77dd39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[index: string, names: string, age: string, total_purchase: string, account_manager: string, years: string, num_sites: string, churn: string, age_square: double, label: int]"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "d5208878",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------------+----+--------------+---------------+-----+---------+-----+----------+-----+\n",
      "|index|           names| age|total_purchase|account_manager|years|num_sites|churn|age_square|label|\n",
      "+-----+----------------+----+--------------+---------------+-----+---------+-----+----------+-----+\n",
      "|    0|Cameron Williams|42.0|       11066.8|              0| 7.22|      8.0|    1|    1764.0|    1|\n",
      "|    1|   Kevin Mueller|41.0|      11916.22|              0|  6.5|     11.0|    1|    1681.0|    1|\n",
      "|    2|     Eric Lozano|38.0|      12884.75|              0| 6.67|     12.0|    1|    1444.0|    1|\n",
      "+-----+----------------+----+--------------+---------------+-----+---------+-----+----------+-----+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark_df.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "1d7ccc51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to set independent variables\n",
    "\n",
    "from pyspark.ml.feature import VectorAssembler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "d449fc4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['index',\n",
       " 'names',\n",
       " 'age',\n",
       " 'total_purchase',\n",
       " 'account_manager',\n",
       " 'years',\n",
       " 'num_sites',\n",
       " 'churn',\n",
       " 'age_square',\n",
       " 'label']"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "848f7d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "dd764bb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(spark_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "cac046e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark_df = spark_df.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "77b1759a",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark_df[['age','total_purchase','account_manager','years','num_sites']] = spark_df[['age','total_purchase','account_manager','years','num_sites']].apply(pd.to_numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "14246f6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(spark_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "d6b45073",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark_df = spark.createDataFrame(spark_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "bd9abebd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(spark_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "de5e4ed0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ind_variables = ['age','total_purchase','account_manager','years','num_sites']\n",
    "# to create an object, we need to all variables convert as a one variable\n",
    "vector_assembler=VectorAssembler(inputCols=ind_variables,outputCol=\"features\")\n",
    "new_df = vector_assembler.transform(spark_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "4fbb53ba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------------+----+--------------+---------------+-----+---------+-----+----------+-----+--------------------+\n",
      "|index|           names| age|total_purchase|account_manager|years|num_sites|churn|age_square|label|            features|\n",
      "+-----+----------------+----+--------------+---------------+-----+---------+-----+----------+-----+--------------------+\n",
      "|    0|Cameron Williams|42.0|       11066.8|              0| 7.22|      8.0|    1|    1764.0|    1|[42.0,11066.8,0.0...|\n",
      "|    1|   Kevin Mueller|41.0|      11916.22|              0|  6.5|     11.0|    1|    1681.0|    1|[41.0,11916.22,0....|\n",
      "|    2|     Eric Lozano|38.0|      12884.75|              0| 6.67|     12.0|    1|    1444.0|    1|[38.0,12884.75,0....|\n",
      "+-----+----------------+----+--------------+---------------+-----+---------+-----+----------+-----+--------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "new_df.show(3) # features represent all independent variables, labes represents dependent variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "b2a346b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[index: string, names: string, age: double, total_purchase: double, account_manager: bigint, years: double, num_sites: double, churn: string, age_square: double, label: bigint, features: vector]"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "c1c75957",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|            features|label|\n",
      "+--------------------+-----+\n",
      "|[42.0,11066.8,0.0...|    1|\n",
      "|[41.0,11916.22,0....|    1|\n",
      "|[38.0,12884.75,0....|    1|\n",
      "+--------------------+-----+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "final_df = new_df.select([\"features\",\"label\"])\n",
    "final_df.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "20bcc9fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[features: vector, label: bigint]"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test-train side \n",
    "splits = final_df.randomSplit([0.7,0.3])\n",
    "train_df=splits[0]\n",
    "test_df=splits[1]\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "63d5800f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[features: vector, label: bigint]"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68ae36c9",
   "metadata": {},
   "source": [
    "# <font color=\"orange\">Customer Churn with GBM (Gradient Boosting Machines)</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c76cd8c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our aim is modelization between dependent and independent variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "d2f69eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import GBTClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "d3059399",
   "metadata": {},
   "outputs": [],
   "source": [
    "gbm=GBTClassifier(featuresCol=\"features\",maxIter=10,labelCol=\"label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "f3553b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "gbm_model=gbm.fit(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "f45b4ac6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://MSI:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.3.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>introduction_to_pyspark</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=local appName=introduction_to_pyspark>"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "443d242b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = gbm_model.transform(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "ad1da832",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[features: vector, label: bigint, rawPrediction: vector, probability: vector, prediction: double]"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "a477a7a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ac = y_pred.select(\"label\",\"prediction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "b4b53f19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8888888888888888"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ac.filter(ac.label == ac.prediction).count() / ac.count() #it compares real and predicted values, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "aa985852",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model tuning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "c298cda9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "\n",
    "evaluator =  BinaryClassificationEvaluator()\n",
    "\n",
    "paramGrid= (ParamGridBuilder()\n",
    "            .addGrid(gbm.maxDepth,[2,4,6])\n",
    "            .addGrid(gbm.maxBins,[20,30])\n",
    "            .addGrid(gbm.maxIter,[10,20])\n",
    "            .build()\n",
    "            )\n",
    "\n",
    "cv = CrossValidator(estimator=gbm, estimatorParamMaps=paramGrid,evaluator=evaluator,numFolds=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "bddc0fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "cvmodel = cv.fit(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eed89b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In big data medium, to predicting we should use transform function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cc3dad0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "cb0bf873",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9007936507936508"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_pred = cvmodel.transform(test_df)\n",
    "ac = final_pred.select(\"label\",\"prediction\")\n",
    "ac.filter(ac.label == ac.prediction).count() / ac.count() # gives true classification rate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "47e1c316",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Column<'prediction'>"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ac.count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "883a6bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for new customer, churn or not ?, here we will apply this model to another dataset \n",
    "\n",
    "names=pd.Series([\"customer1\",\"customer2\",\"customer3\",\"customer4\",\"customer5\"])\n",
    "age=pd.Series([38,43,34,50,40])\n",
    "total_purchase = pd.Series([30000,10000,6000,30000,100000])\n",
    "account_manager=([1,0,0,1,1])\n",
    "years = pd.Series([20,10,3,8,30])\n",
    "num_sites=pd.Series([30,8,8,6,50])\n",
    "\n",
    "new_customers=pd.DataFrame({\"names\":names,\n",
    "                            \"age\":age,\n",
    "                            \"total_purchase\":total_purchase,\n",
    "                           \"account_manager\":account_manager,\n",
    "                           \"years\":years,\n",
    "                           \"num_sites\":num_sites})\n",
    "new_customers.columns\n",
    "# this dataframe is created by us, we need to convert it to a version which is compatible with spark\n",
    "\n",
    "new_sdf = spark.createDataFrame(new_customers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "927128d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---+--------------+---------------+-----+---------+\n",
      "|    names|age|total_purchase|account_manager|years|num_sites|\n",
      "+---------+---+--------------+---------------+-----+---------+\n",
      "|customer1| 38|         30000|              1|   20|       30|\n",
      "|customer2| 43|         10000|              0|   10|        8|\n",
      "|customer3| 34|          6000|              0|    3|        8|\n",
      "|customer4| 50|         30000|              1|    8|        6|\n",
      "|customer5| 40|        100000|              1|   30|       50|\n",
      "+---------+---+--------------+---------------+-----+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "new_sdf.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7885e8bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need to convert it an appropriate version of model, so we need to convert it to vector "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "5a1f4c85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---+--------------+---------------+-----+---------+--------------------+\n",
      "|    names|age|total_purchase|account_manager|years|num_sites|            features|\n",
      "+---------+---+--------------+---------------+-----+---------+--------------------+\n",
      "|customer1| 38|         30000|              1|   20|       30|[38.0,30000.0,1.0...|\n",
      "|customer2| 43|         10000|              0|   10|        8|[43.0,10000.0,0.0...|\n",
      "|customer3| 34|          6000|              0|    3|        8|[34.0,6000.0,0.0,...|\n",
      "|customer4| 50|         30000|              1|    8|        6|[50.0,30000.0,1.0...|\n",
      "|customer5| 40|        100000|              1|   30|       50|[40.0,100000.0,1....|\n",
      "+---------+---+--------------+---------------+-----+---------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "new_customers = vector_assembler.transform(new_sdf)\n",
    "new_customers.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "898b3c9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[names: string, age: bigint, total_purchase: bigint, account_manager: bigint, years: bigint, num_sites: bigint, features: vector, rawPrediction: vector, probability: vector, prediction: double]"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = cvmodel.transform(new_customers) # prediction\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "5840a44d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+\n",
      "|    names|prediction|\n",
      "+---------+----------+\n",
      "|customer1|       1.0|\n",
      "|customer2|       0.0|\n",
      "|customer3|       0.0|\n",
      "|customer4|       0.0|\n",
      "|customer5|       1.0|\n",
      "+---------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results.select(\"names\",\"prediction\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "092ae8b0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
